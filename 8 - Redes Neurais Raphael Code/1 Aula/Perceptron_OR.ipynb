{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6PUrEWNVokTq"
   },
   "source": [
    "# Perceptron OR Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nAIALPgZorpy"
   },
   "source": [
    "## Setting up the environmentm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "221D3b0Koydg"
   },
   "source": [
    "The Keras framework has been implemented inside the Google Tensorflow API on version 2.0. The Keras framework takes advantage of the optimizations for GPU and also TPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9jT907oHpabg"
   },
   "source": [
    "The first thing we should do is to update Google Colab tensorflow version <strong>this has to be done at every notebook created</strong>. The tool we'll be using for that is the `pip` tool. It is important that we restart the environment after finishing the installation;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 627
    },
    "colab_type": "code",
    "id": "dHJ4WOQIyalz",
    "outputId": "5ce5dbb6-9cd0-4f86-8760-88594f0dbf96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/5c/f1d66de5dde6f3ff528f6ea1fd0757a0e594d17debb3ec7f82daa967ea9a/tensorflow-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (86.3MB)\n",
      "\u001b[K     |████████████████████████████████| 86.3MB 86kB/s  eta 0:00:011    |█████████████████████████▌      | 68.7MB 6.3MB/s eta 0:00:03\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/83/755bd5324777875e9dff19c2e59daec837d0378c09196634524a3d7269ac/opt_einsum-3.1.0.tar.gz (69kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 391kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /home/hub/anaconda3/envs/fiep/lib/python3.7/site-packages (from tensorflow==2) (0.33.6)\n",
      "Collecting google-pasta>=0.1.6\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/fd/1e86bc4837cc9a3a5faf3db9b1854aa04ad35b5f381f9648fbe81a6f94e4/google_pasta-0.1.8-py3-none-any.whl (57kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 396kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<2.1.0,>=2.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 2.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.1.0,>=2.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 3.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf>=3.6.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/f1/8dcd4219bbae8aa44fe8871a89f05eca2dca9c04f8dbfed8a82b7be97a88/protobuf-3.11.3-cp37-cp37m-manylinux1_x86_64.whl (1.3MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3MB 3.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /home/hub/anaconda3/envs/fiep/lib/python3.7/site-packages (from tensorflow==2) (1.11.2)\n",
      "Collecting keras-preprocessing>=1.0.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 357kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting gast==0.2.2\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Collecting absl-py>=0.7.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz (104kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 7.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /home/hub/anaconda3/envs/fiep/lib/python3.7/site-packages (from tensorflow==2) (1.18.1)\n",
      "Collecting grpcio>=1.8.6\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/00/997acb1c16f84e6d3ede511500f54e7b7a1fdfe7b4da5a5c2d07ad4e91f1/grpcio-1.27.2-cp37-cp37m-manylinux2010_x86_64.whl (2.7MB)\n",
      "\u001b[K     |████████████████████████████████| 2.7MB 1.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-applications>=1.0.8\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 227kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Requirement already satisfied: six>=1.10.0 in /home/hub/anaconda3/envs/fiep/lib/python3.7/site-packages (from tensorflow==2) (1.13.0)\n",
      "Collecting astor>=0.6.0\n",
      "  Downloading https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/8d/e2ebbd0502627ed0d8a408162020e1c0792f088b49fddeedaaeebc206ed7/google_auth-1.11.2-py2.py3-none-any.whl (76kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 588kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /home/hub/anaconda3/envs/fiep/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2) (44.0.0.post20200106)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/hub/anaconda3/envs/fiep/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2) (0.16.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/hub/anaconda3/envs/fiep/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2) (2.22.0)\n",
      "Collecting markdown>=2.6.8\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/c4/ba46d44855e6eb1770a12edace5a165a0c6de13349f592b9036257f3c3d3/Markdown-3.2.1-py2.py3-none-any.whl (88kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 623kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: h5py in /home/hub/anaconda3/envs/fiep/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==2) (2.9.0)\n",
      "Collecting rsa<4.1,>=3.1.4\n",
      "  Downloading https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/08/6a/abf83cb951617793fd49c98cb9456860f5df66ff89883c8660aa0672d425/cachetools-4.0.0-py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl (155kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 5.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/hub/anaconda3/envs/fiep/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hub/anaconda3/envs/fiep/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/hub/anaconda3/envs/fiep/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/hub/anaconda3/envs/fiep/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2) (1.25.7)\n",
      "Collecting pyasn1>=0.1.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl (77kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 601kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 4.7MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: opt-einsum, gast, absl-py, termcolor\n",
      "  Building wheel for opt-einsum (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for opt-einsum: filename=opt_einsum-3.1.0-cp37-none-any.whl size=61682 sha256=001e0b43d42d5c47123d78091a24b65eb5081473bdaf4395f932001a7500eaba\n",
      "  Stored in directory: /home/hub/.cache/pip/wheels/2c/b1/94/43d03e130b929aae7ba3f8d15cbd7bc0d1cb5bb38a5c721833\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=6c60e70f258d215b8a52c53f17404250afbec4c2a5a531d747c89204f3061e57\n",
      "  Stored in directory: /home/hub/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for absl-py: filename=absl_py-0.9.0-cp37-none-any.whl size=121932 sha256=6a7e1c4f84a02b9ae603ac1857ba26fb0b39dbf7f5a59f7f75e097ab40a41f3b\n",
      "  Stored in directory: /home/hub/.cache/pip/wheels/8e/28/49/fad4e7f0b9a1227708cbbee4487ac8558a7334849cb81c813d\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-cp37-none-any.whl size=4832 sha256=42e90403c15575241ff63e7a17385fee088c9ebaae52cd67afbd170e97d6c435\n",
      "  Stored in directory: /home/hub/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "Successfully built opt-einsum gast absl-py termcolor\n",
      "Installing collected packages: opt-einsum, google-pasta, pyasn1, rsa, cachetools, pyasn1-modules, google-auth, protobuf, grpcio, oauthlib, requests-oauthlib, google-auth-oauthlib, absl-py, markdown, tensorboard, tensorflow-estimator, keras-preprocessing, gast, keras-applications, termcolor, astor, tensorflow\n",
      "Successfully installed absl-py-0.9.0 astor-0.8.1 cachetools-4.0.0 gast-0.2.2 google-auth-1.11.2 google-auth-oauthlib-0.4.1 google-pasta-0.1.8 grpcio-1.27.2 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.2.1 oauthlib-3.1.0 opt-einsum-3.1.0 protobuf-3.11.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.0 tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow==2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Bc7WV0-orDGD",
    "outputId": "c127254e-f8e3-4519-965b-e52b570740ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__) # Check the version of the tensorflow library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N8Sij0G6rUTl"
   },
   "source": [
    "## Create the input dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fcyzAnTWqwmD"
   },
   "source": [
    "We will also use numpy, thus the import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ULE81emgz6UJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sEEkkPNGrRbo"
   },
   "source": [
    "Create the truth table for the OR operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pYMrkZFHzpPd"
   },
   "outputs": [],
   "source": [
    "or_truth_table = np.array([[0,0,0],\n",
    "                           [0,1,1],\n",
    "                           [1,0,1],\n",
    "                           [1,1,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hAQV_w2t1f6G"
   },
   "source": [
    "## Creating a Sequential Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G8Tam5marvDM"
   },
   "source": [
    "Import and instantiate the Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-DbQsrWI0ni7"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5vrCZuKD2HSk"
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "blzcsuqQ2Kyl"
   },
   "source": [
    "Create a layer with a single neuron. The Dense layer represents a layer of neurons that are completely interconnected with the previous and next layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6wybhR07IsVE"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9LgWjpBV2TDJ"
   },
   "outputs": [],
   "source": [
    "model.add(Dense(units=1, input_dim=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zw1NEsq-I4QG"
   },
   "source": [
    "Now we need to compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7liXdyW6JTRF"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5jffX5UztszI"
   },
   "source": [
    "Split our dataset into input and expected values;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C7v6XDjsKUmB"
   },
   "outputs": [],
   "source": [
    "X_data = or_truth_table[:,[0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ZHBR8jWMT_D"
   },
   "outputs": [],
   "source": [
    "Y_data = or_truth_table[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bXIiKqPjt2Tw"
   },
   "source": [
    "Perform the training (`fit`) operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8ymAEEXMMggw",
    "outputId": "b563ae02-87f0-47b5-963c-90b67ff9f054"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4a47aa97f0>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_data, y=Y_data, epochs=200, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0PgSY7Det78o"
   },
   "source": [
    "Check the error value (`loss`) when predicting using the dataset, i.e., how far off we are from the correct answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "gBIv_FYXMvZx",
    "outputId": "22fa1f4a-8acd-4ff8-9cd5-0b35cde34eb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "4/1 [========================================================================================================================] - 0s 599us/sample - loss: 0.0819\n",
      "0.08190849423408508\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_data, Y_data)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2zwyVJqIuS52"
   },
   "source": [
    "Now it is time to make predictions using our trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5a9WUbyQNJ0l"
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "TMG4hM3aNVFd",
    "outputId": "edd5c1ff-9e4d-4784-b5d5-d28f78c95d89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.28700256]\n",
      " [0.75856614]\n",
      " [0.75304747]\n",
      " [1.224611  ]]\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C3KFfN38uj2H"
   },
   "source": [
    "Convert the output to the desired format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "FL802cvMuoQU",
    "outputId": "42b95303-027c-4cc7-d64e-af800385f707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yGdCGC07N8dV",
    "outputId": "da474788-2f4c-42e3-c1c5-0a4eb6209d98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(Y_data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Perceptron_OR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
